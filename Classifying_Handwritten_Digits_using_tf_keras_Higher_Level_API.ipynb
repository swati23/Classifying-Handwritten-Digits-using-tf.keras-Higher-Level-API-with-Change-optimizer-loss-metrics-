{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classifying Handwritten Digits using tf.keras Higher Level API.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swati23/Classifying-Handwritten-Digits-using-tf.keras-Higher-Level-API-with-Change-optimizer-loss-metrics-/blob/master/Classifying_Handwritten_Digits_using_tf_keras_Higher_Level_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9cAPp_UTsTI",
        "colab_type": "text"
      },
      "source": [
        "**Classifying Handwritten Digits using tf.keras Higher Level API:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uYcofgiOVKo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ed7f7277-0079-4d43-9264-63338a5cb803"
      },
      "source": [
        "!date"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Jun 29 17:13:09 UTC 2019\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yshgGbQcOcnp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "79cfffff-1295-44b2-cb79-9a6e2b80b853"
      },
      "source": [
        "%%shell\n",
        "mkdir test\n",
        "ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data  test\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urceRsOgOlVg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "eb39c070-eaab-4e78-9f48-17058f97ca81"
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.0-alpha"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu==2.0.0-alpha in /usr/local/lib/python3.6/dist-packages (2.0.0a0)\n",
            "Requirement already satisfied: google-pasta>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha) (0.1.7)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha) (0.2.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha) (1.0.8)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha) (1.12.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha) (0.7.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha) (1.1.0)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha) (1.14.0.dev2019030115)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha) (0.8.0)\n",
            "Requirement already satisfied: tb-nightly<1.14.0a20190302,>=1.14.0a20190301 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha) (1.14.0a20190301)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha) (1.16.4)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha) (0.33.4)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha) (3.7.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-alpha) (2.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha) (0.15.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha) (3.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-alpha) (41.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPtF_VIAOlYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals #forces Python interpreter to use newer features of the language.\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxAWOKwDOlar",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d6406cc-cc00-4e2a-c80c-43be650443a6"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-alpha0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qehw8j5uPBMX",
        "colab_type": "text"
      },
      "source": [
        "tf.keras.optimizers - various optimizers for machine learning algorithms like ADAM, RMSprop etc\n",
        "tf.keras.metrics - various metrics for judging the goodness of model\n",
        "tf.keras.losses - to reduce the error in prediction during the optimization process\n",
        "tf.keras.layers - various layers for building Deep Neural Networks like Conv1D, Dense, Dropout, Embedding, GRU ***\n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JhK9eJHOldE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b6630e8d-dd64-43c4-8355-763c5cbd7201"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0 #normalizing input"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggOlTzfWPgn7",
        "colab_type": "text"
      },
      "source": [
        "Finding the shape of x_train, x_test, y_train and y_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRQqOWYJOlfd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "75ef301d-861b-43b3-a38c-6624e7bec0c0"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNuDCXEHPojv",
        "colab_type": "text"
      },
      "source": [
        "Create a Sequential Model using tf.keras.layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWJslWh_OliE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfH1z5sqPvHe",
        "colab_type": "text"
      },
      "source": [
        "Training and evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZm8bsX4Olkq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "ffe680f1-3a5a-4174-fe3b-341d205848e6"
      },
      "source": [
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.2974 - accuracy: 0.9136\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 6s 104us/sample - loss: 0.1430 - accuracy: 0.9572\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 6s 98us/sample - loss: 0.1103 - accuracy: 0.9666\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 6s 102us/sample - loss: 0.0886 - accuracy: 0.9724\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0783 - accuracy: 0.9752\n",
            "10000/10000 [==============================] - 0s 46us/sample - loss: 0.0693 - accuracy: 0.9783\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06926563136065379, 0.9783]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpIycJk0P9q0",
        "colab_type": "text"
      },
      "source": [
        "## **Change optimizer, loss, metrics of the above model by exploring tf.keras API**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyYjZj7APyFL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy']\n",
        "             )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nv49rnUjQ340",
        "colab_type": "text"
      },
      "source": [
        "### **Create a Deep Learning Model to predict housing prices using the built-in Boston Housing dataset of tf.keras API**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zP-9KDc2QFnX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "39f7d8ee-07d1-4c36-cb54-74b69de4b9df"
      },
      "source": [
        "#Load Dataset\n",
        "!wget https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/datasets/boston_housing\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-29 17:31:15--  https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/datasets/boston_housing\n",
            "Resolving www.tensorflow.org (www.tensorflow.org)... 74.125.141.102, 74.125.141.101, 74.125.141.139, ...\n",
            "Connecting to www.tensorflow.org (www.tensorflow.org)|74.125.141.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 697387 (681K) [text/html]\n",
            "Saving to: ‘boston_housing’\n",
            "\n",
            "\rboston_housing        0%[                    ]       0  --.-KB/s               \rboston_housing      100%[===================>] 681.04K  3.48MB/s    in 0.2s    \n",
            "\n",
            "2019-06-29 17:31:15 (3.48 MB/s) - ‘boston_housing’ saved [697387/697387]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPe1CQuzRDbY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "172309a8-e65f-4674-f643-e8f8aae4ffda"
      },
      "source": [
        "#no changes need to be done here\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "model.fit(x_train, y_train, epochs=50)\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 7s 109us/sample - loss: 0.3018 - accuracy: 0.9127\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 6s 98us/sample - loss: 0.1466 - accuracy: 0.9565\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 6s 101us/sample - loss: 0.1110 - accuracy: 0.9668\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 0.0914 - accuracy: 0.9728\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 0.0757 - accuracy: 0.9762\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 0.0668 - accuracy: 0.9788\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 0.0594 - accuracy: 0.9810\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0536 - accuracy: 0.9822\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 0.0497 - accuracy: 0.9837\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 0.0462 - accuracy: 0.9853\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 6s 102us/sample - loss: 0.0436 - accuracy: 0.9852\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 6s 101us/sample - loss: 0.0417 - accuracy: 0.9862\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 0.0375 - accuracy: 0.9875\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 0.0352 - accuracy: 0.9883\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 6s 101us/sample - loss: 0.0333 - accuracy: 0.9887\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 0.0320 - accuracy: 0.9889\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 6s 102us/sample - loss: 0.0302 - accuracy: 0.9894\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 6s 102us/sample - loss: 0.0291 - accuracy: 0.9902\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0282 - accuracy: 0.9904\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0279 - accuracy: 0.9905\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0258 - accuracy: 0.9907\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0257 - accuracy: 0.9912\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 0.0263 - accuracy: 0.9910\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 6s 102us/sample - loss: 0.0246 - accuracy: 0.9915\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0223 - accuracy: 0.9919\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0212 - accuracy: 0.9929\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 0.0225 - accuracy: 0.9918\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0224 - accuracy: 0.9924\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 0.0212 - accuracy: 0.9925\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 6s 97us/sample - loss: 0.0204 - accuracy: 0.9930\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0197 - accuracy: 0.9930\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 6s 101us/sample - loss: 0.0198 - accuracy: 0.9934\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 0.0180 - accuracy: 0.9938\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 6s 95us/sample - loss: 0.0201 - accuracy: 0.9931\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0200 - accuracy: 0.9930\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0194 - accuracy: 0.9933\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 0.0187 - accuracy: 0.9937\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 0.0183 - accuracy: 0.9937\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 6s 97us/sample - loss: 0.0203 - accuracy: 0.9928\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0171 - accuracy: 0.9941\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 6s 97us/sample - loss: 0.0178 - accuracy: 0.9936\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 6s 96us/sample - loss: 0.0162 - accuracy: 0.9944\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0166 - accuracy: 0.9943\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 6s 97us/sample - loss: 0.0170 - accuracy: 0.9940\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 0.0164 - accuracy: 0.9941\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 6s 97us/sample - loss: 0.0167 - accuracy: 0.9945\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 6s 95us/sample - loss: 0.0161 - accuracy: 0.9948\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 6s 97us/sample - loss: 0.0161 - accuracy: 0.9947\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0157 - accuracy: 0.9948\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 6s 95us/sample - loss: 0.0160 - accuracy: 0.9945\n",
            "10000/10000 [==============================] - 0s 48us/sample - loss: 0.1215 - accuracy: 0.9803\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.12151158882936663, 0.9803]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGi1VrpJS1gq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "886c0e18-f8a3-413c-d7f5-04d587731c71"
      },
      "source": [
        "print('Predicted Price {}'.format(model.predict(x_test[20].reshape(-1,13))))#to convert 2 dimensional matrix x_test to single dimensional vector having 13 elements\n",
        "print('Actual Price {}'.format(y_test[20]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-6a5fb46749cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predicted Price {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#to convert 2 dimensional matrix x_test to single dimensional vector having 13 elements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Actual Price {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 784 into shape (13)"
          ]
        }
      ]
    }
  ]
}